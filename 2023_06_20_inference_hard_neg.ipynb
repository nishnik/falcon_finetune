{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52e49d16-d37c-40ee-ae4a-6473924c9f8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T09:04:48.228904Z",
     "iopub.status.busy": "2023-06-20T09:04:48.228637Z",
     "iopub.status.idle": "2023-06-20T09:04:48.304785Z",
     "shell.execute_reply": "2023-06-20T09:04:48.304208Z",
     "shell.execute_reply.started": "2023-06-20T09:04:48.228883Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Literal\n",
    "\n",
    "import lightning as L\n",
    "import torch\n",
    "from lightning.fabric.strategies import FSDPStrategy\n",
    "from torch.distributed.fsdp.wrap import transformer_auto_wrap_policy\n",
    "\n",
    "# support running without installing as a package\n",
    "# wd = Path(__file__).parent.parent.resolve()\n",
    "# sys.path.append(str(wd))\n",
    "\n",
    "from generate.base import generate\n",
    "from lit_parrot import Tokenizer\n",
    "from lit_parrot.adapter import Block\n",
    "from lit_parrot.adapter import Parrot, Config\n",
    "from lit_parrot.adapter_v2 import add_adapter_v2_parameters_to_linear_layers\n",
    "from lit_parrot.utils import lazy_load, check_valid_checkpoint_dir, quantization\n",
    "from scripts.prepare_alpaca import generate_prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d6c80f-388f-491e-aa2e-2c3c85c42d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(\n",
    "    prompt: str = \"What food do lamas eat?\",\n",
    "    input: str = \"\",\n",
    "    adapter_path: Path = Path(\"out/adapter_v2/alpaca/lit_model_adapter_finetuned.pth\"),\n",
    "    checkpoint_dir: Path = Path(f\"checkpoints/stabilityai/stablelm-base-alpha-3b\"),\n",
    "    quantize: Literal[\"llm.int8\", \"gptq.int4\"] = None,\n",
    "    max_new_tokens: int = 100,\n",
    "    top_k: int = 200,\n",
    "    temperature: float = 0.8,\n",
    "    strategy: str = \"auto\",\n",
    "    devices: int = 1,\n",
    "    precision: str = \"bf16-true\",\n",
    ") -> None:\n",
    "    \"\"\"Generates a response based on a given instruction and an optional input.\n",
    "    This script will only work with checkpoints from the instruction-tuned Parrot-AdapterV2 model.\n",
    "    See `finetune/adapter_v2.py`.\n",
    "\n",
    "    Args:\n",
    "        prompt: The prompt/instruction (Alpaca style).\n",
    "        adapter_path: Path to the checkpoint with trained adapter weights, which are the output of\n",
    "            `finetune/adapter_v2.py`.\n",
    "        checkpoint_dir: The path to the checkpoint folder with pretrained Parrot weights.\n",
    "        input: Optional input (Alpaca style).\n",
    "        quantize: Whether to quantize the model and using which method:\n",
    "            ``\"llm.int8\"``: LLM.int8() mode,\n",
    "            ``\"gptq.int4\"``: GPTQ 4-bit mode.\n",
    "        max_new_tokens: The number of generation steps to take.\n",
    "        top_k: The number of top most probable tokens to consider in the sampling process.\n",
    "        temperature: A value controlling the randomness of the sampling process. Higher values result in more random\n",
    "            samples.\n",
    "        strategy: Indicates the Fabric strategy setting to use.\n",
    "        devices: How many devices to use.\n",
    "        precision: Indicates the Fabric precision setting to use.\n",
    "    \"\"\"\n",
    "    if strategy == \"fsdp\":\n",
    "        auto_wrap_policy = partial(transformer_auto_wrap_policy, transformer_layer_cls={Block})\n",
    "        strategy = FSDPStrategy(auto_wrap_policy=auto_wrap_policy, cpu_offload=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fdb8874-3123-46ee-8f00-f50d9568699d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T09:07:49.986927Z",
     "iopub.status.busy": "2023-06-20T09:07:49.986650Z",
     "iopub.status.idle": "2023-06-20T09:08:24.556087Z",
     "shell.execute_reply": "2023-06-20T09:08:24.553074Z",
     "shell.execute_reply.started": "2023-06-20T09:07:49.986906Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Loading model 'checkpoints/tiiuae/falcon-7b/lit_model.pth' with {'block_size': 2048, 'vocab_size': 50254, 'padding_multiple': 512, 'padded_vocab_size': 65024, 'n_layer': 32, 'n_head': 71, 'n_embd': 4544, 'rotary_percentage': 1.0, 'parallel_residual': True, 'bias': False, 'n_query_groups': 1, 'shared_attention_norm': True, 'adapter_prompt_length': 10, 'adapter_start_layer': 2}\n",
      "Time to instantiate model: 1.45 seconds.\n",
      "Time to load the model weights: 33.09 seconds.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "checkpoint_dir = Path(\"checkpoints/tiiuae/falcon-7b\")\n",
    "adapter_path = Path(\"out/adapter/alpaca/lit_model_adapter_finetuned.pth\")\n",
    "\n",
    "quantize: Literal[\"llm.int8\", \"gptq.int4\"] = None\n",
    "max_new_tokens: int = 100\n",
    "top_k: int = 200\n",
    "temperature: float = 0.8\n",
    "strategy: str = \"auto\"\n",
    "devices: int = 1\n",
    "precision: str = \"bf16-true\"\n",
    "\n",
    "fabric = L.Fabric(devices=devices, precision=precision, strategy=strategy)\n",
    "fabric.launch()\n",
    "\n",
    "check_valid_checkpoint_dir(checkpoint_dir)\n",
    "\n",
    "with open(checkpoint_dir / \"lit_config.json\") as fp:\n",
    "    config = Config(**json.load(fp))\n",
    "\n",
    "if quantize is not None and devices > 1:\n",
    "    raise NotImplementedError\n",
    "if quantize == \"gptq.int4\":\n",
    "    model_file = \"lit_model_gptq.4bit.pth\"\n",
    "    if not (checkpoint_dir / model_file).is_file():\n",
    "        raise ValueError(\"Please run `python quantize/gptq.py` first\")\n",
    "else:\n",
    "    model_file = \"lit_model.pth\"\n",
    "\n",
    "checkpoint_path = checkpoint_dir / model_file\n",
    "\n",
    "fabric.print(f\"Loading model {str(checkpoint_path)!r} with {config.__dict__}\", file=sys.stderr)\n",
    "t0 = time.time()\n",
    "with fabric.init_module(empty_init=True), quantization(quantize):\n",
    "    model = Parrot(config)\n",
    "    add_adapter_v2_parameters_to_linear_layers(model)\n",
    "fabric.print(f\"Time to instantiate model: {time.time() - t0:.02f} seconds.\", file=sys.stderr)\n",
    "\n",
    "t0 = time.time()\n",
    "with lazy_load(checkpoint_path) as checkpoint, lazy_load(adapter_path) as adapter_checkpoint:\n",
    "    checkpoint.update(adapter_checkpoint)\n",
    "    model.load_state_dict(checkpoint, strict=quantize is None)\n",
    "fabric.print(f\"Time to load the model weights: {time.time() - t0:.02f} seconds.\", file=sys.stderr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dee07b8d-e0f9-48bc-abff-e76e589c7f36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T09:09:20.703828Z",
     "iopub.status.busy": "2023-06-20T09:09:20.703289Z",
     "iopub.status.idle": "2023-06-20T09:09:24.210570Z",
     "shell.execute_reply": "2023-06-20T09:09:24.209703Z",
     "shell.execute_reply.started": "2023-06-20T09:09:20.703807Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = Path(\"data/alpaca\")\n",
    "\n",
    "train_data = torch.load(data_dir / \"train.pt\")\n",
    "val_data = torch.load(data_dir / \"test.pt\")\n",
    "tokenizer = Tokenizer(checkpoint_dir / \"tokenizer.json\", checkpoint_dir / \"tokenizer_config.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40b7c43b-ad6a-4f68-9750-62cd1dcb382e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T09:14:40.725884Z",
     "iopub.status.busy": "2023-06-20T09:14:40.725268Z",
     "iopub.status.idle": "2023-06-20T09:14:40.728256Z",
     "shell.execute_reply": "2023-06-20T09:14:40.727781Z",
     "shell.execute_reply.started": "2023-06-20T09:14:40.725861Z"
    }
   },
   "outputs": [],
   "source": [
    "micro_batch_size = 1\n",
    "max_seq_length = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bd8844a-4328-400a-8d0b-01c282c1f995",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T09:14:40.926332Z",
     "iopub.status.busy": "2023-06-20T09:14:40.925894Z",
     "iopub.status.idle": "2023-06-20T09:14:40.932593Z",
     "shell.execute_reply": "2023-06-20T09:14:40.931968Z",
     "shell.execute_reply.started": "2023-06-20T09:14:40.926309Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_batch(fabric: L.Fabric, data: list, max_seq_length: int, deterministic: bool, iter_num: int = 0):\n",
    "    if deterministic:\n",
    "        ix = torch.arange(iter_num*micro_batch_size, (iter_num + 1)*micro_batch_size)\n",
    "    else:\n",
    "        ix = torch.randint(len(data), (micro_batch_size,))\n",
    "\n",
    "    input_ids = [data[i][\"input_ids\"].type(torch.int64) for i in ix]\n",
    "    labels = [data[i][\"labels\"].type(torch.int64) for i in ix]\n",
    "\n",
    "\n",
    "    max_len = max(len(s) for s in input_ids) if fabric.device.type != \"xla\" else max_seq_length\n",
    "    def pad_right(x, pad_id):\n",
    "        # pad right based on the longest sequence\n",
    "        n = max_len - len(x)\n",
    "        return torch.cat((x, torch.full((n,), pad_id, dtype=x.dtype)))\n",
    "\n",
    "    x = torch.stack([pad_right(x, pad_id=0) for x in input_ids])\n",
    "    y = torch.stack([pad_right(x, pad_id=-1) for x in labels])\n",
    "\n",
    "    if fabric.device.type in (\"mps\", \"xla\"):\n",
    "        x, y = fabric.to_device((x, y))\n",
    "    else:\n",
    "        x, y = fabric.to_device((x.pin_memory(), y.pin_memory()))\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9470a7b0-6ca0-485f-9a31-4faa303b5df9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T09:14:59.484080Z",
     "iopub.status.busy": "2023-06-20T09:14:59.483802Z",
     "iopub.status.idle": "2023-06-20T09:14:59.488270Z",
     "shell.execute_reply": "2023-06-20T09:14:59.487470Z",
     "shell.execute_reply.started": "2023-06-20T09:14:59.484063Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_fn(logits, targets):\n",
    "    # shift the targets such that output n predicts token n+1\n",
    "    logits = logits[..., :-1, :].contiguous()\n",
    "    targets = targets[..., 1:].contiguous()\n",
    "    loss = torch.nn.functional.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d3bc527-2687-484f-a208-d90127fa86ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T09:40:09.955084Z",
     "iopub.status.busy": "2023-06-20T09:40:09.954462Z",
     "iopub.status.idle": "2023-06-20T09:40:09.959408Z",
     "shell.execute_reply": "2023-06-20T09:40:09.958766Z",
     "shell.execute_reply.started": "2023-06-20T09:40:09.955061Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87109375"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "24a32b0e-40ce-43ff-91dc-211b9e7483fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T09:44:53.233125Z",
     "iopub.status.busy": "2023-06-20T09:44:53.232495Z",
     "iopub.status.idle": "2023-06-20T09:46:26.670742Z",
     "shell.execute_reply": "2023-06-20T09:46:26.670039Z",
     "shell.execute_reply.started": "2023-06-20T09:44:53.233098Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:33<00:00, 21.41it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "data = val_data\n",
    "losses = torch.zeros(len(data))\n",
    "data_and_loss = []\n",
    "for k in tqdm.trange(len(data)):\n",
    "    input_ids, targets = get_batch(fabric, data, max_seq_length, True, k)\n",
    "    logits = model(input_ids)\n",
    "    loss = loss_fn(logits, targets)\n",
    "    losses[k] = loss.item()\n",
    "    data_and_loss.append(\n",
    "        {\n",
    "            \"data\": tokenizer.processor.decode(input_ids.tolist()[0]),\n",
    "            \"loss\": losses[k].item()\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b0f00ba-f449-4d5c-baf6-af9bcf29e805",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T09:46:29.364677Z",
     "iopub.status.busy": "2023-06-20T09:46:29.363885Z",
     "iopub.status.idle": "2023-06-20T09:46:29.391087Z",
     "shell.execute_reply": "2023-06-20T09:46:29.390416Z",
     "shell.execute_reply.started": "2023-06-20T09:46:29.364655Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data_and_loss)\n",
    "df.to_csv(\"neg_mining/06_20_val_out_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "219cb4a6-ac5e-47c2-a852-becb2eede6dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T09:47:21.911194Z",
     "iopub.status.busy": "2023-06-20T09:47:21.910519Z",
     "iopub.status.idle": "2023-06-20T09:47:21.917334Z",
     "shell.execute_reply": "2023-06-20T09:47:21.916523Z",
     "shell.execute_reply.started": "2023-06-20T09:47:21.911170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet that allows the user to input a first name with a width of 8 columns and inserts it into a sentence stating that the person cannot participate in grade-appropriate writing assignments in English.\\n\\n### Response:{formtext: name=first name; cols=8} cannot participate meaningfully in grade appropriate writing assignments in English.',\n",
       "        2.28125],\n",
       "       ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet that generates an apology email for delayed response. The snippet should include a placeholder for the expected timeframe for processing the request. Use appropriate TextBlaze templates to create the placeholders.\\n\\n### Response:Please accept our apologies for the delay in replying to your emails. Our backend systems went down and as a result, we couldn’t process your request under usual processing times. Our systems are back up now and we expect to process your request within {formtext: name=timeframe; cols=10}.',\n",
       "        2.3125],\n",
       "       ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet that loads a Coda table using the Coda API. Prompt the user to enter their API key and the document ID. Display a dropdown menu of available tables in the document. When the user selects a table, display the table ID.\\n\\n### Response:{API_KEY=\"Replace with your API key\"}\\n    {doc_id=\"IU9zjBEyAV\"}\\n    {urlload: https://coda.io/apis/v1/docs/{=doc_id}/tables; method=GET; done=(res) ->[\"tables\":catch(fromJSON(res)[\"items\"], \"???\")]; headers=Authorization: Bearer {=personal_access_token}}\\n    {formmenu: default=Please select a table; name=selected_table_name; values={=map(tables, table->table[\"name\"])}}\\n    {if: selected_table_name <> \"Please select a table\"}\\n    {selected_table=filter(tables, table->table[\"name\"]=={=selected_table_name})[1]}\\n    {selected_table_id=selected_table[\"id\"]}\\n    Table ID: {=selected_table_id}\\n    {endif}',\n",
       "        2.3125],\n",
       "       [\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet for a beginner's writing class that allows the teacher to input a student's name and a comment on their writing. The comment should indicate that the student has a basic understanding of English writing conventions. The snippet should include a form field for the student's name and a form field for the comment.\\n\\n### Response:Comentario para boletín de notas de “writing” para principiantes 3\\n\\n{formtext: name= nombre; cols=9} demuestra mínimo entendimiento de las convenciones escritas del Inglés.\",\n",
       "        2.328125],\n",
       "       ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet that updates a product to be sold by case quantity. Use {formtext} to get the case quantity, and insert it into the product title and multiply the cost, price, and weight by the case quantity. Use {endform} to notify when done.\\n\\n### Response:Please update this product to be sold by case quantity.\\n\\nCase Quantity is: {formtext: name=casequantity; default=10; cols=5}\\nPlease add \"- Case of {=`casequantity`}\" to the product title\\nPlease multiply the Cost and Price on vendor site or price list by {=`casequantity`} and set in Shopify\\nPlease multiply weight by {=`casequantity`}\\nNotify me when done',\n",
       "        2.328125],\n",
       "       ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet that allows the user to input a first name with a width of 8 columns and outputs a sentence stating that the first name is doing well with verbal expressions in English. Use the appropriate {{TextBlaze template}} for the input field.\\n\\n### Response:{formtext: name=first name; cols=8} is doing well with verbal expressions in English.',\n",
       "        2.328125],\n",
       "       ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet for a thank you email with placeholders for recipient name, a brief mention of a topic, a suggestion related to the topic, a specific suggestion, a date to follow up, and a signature. Use appropriate TextBlaze templates for each placeholder.\\n\\n### Response:Plantilla de correo de agradecimiento 4\\n\\nHola {formtext: name=nombre; cols= 8}, \\n<br><br>\\nFue un placer conocerle en Dreamforce 2021. Has mencionado brevemente [tema mencionado por el destinatario], ¿has pensado en [sugerencia en torno al tema]?\\n<br><br>\\nCreo que {formtext: name=sugerencia; cols=30} específica se ajustaría perfectamente a [tema mencionado por el receptor]\\n<br><br>\\nVolvamos a hablar el {formdate: LL} si estás disponible. \\n<br><br>\\n[Añada su firma de correo electrónico aquí].',\n",
       "        2.328125],\n",
       "       ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet that inserts a Spanish sentence thanking the user for their patience and asking for a reason for the delay using a TextBlaze template. The developer should choose the appropriate TextBlaze template to capture the reason.\\n\\n### Response:Gracias por su paciencia mientras estudiamos su solicitud. Nos ha llevado más tiempo del previsto porque {formtext: name=añadir razón}.',\n",
       "        2.34375],\n",
       "       [\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet that prompts the user to input a name with a text field of 9 columns, followed by a sentence that describes the user's behavior in a specific subject.\\n\\n### Response:{formtext: name= nombre; cols=9} se precipita en los problemas de matemáticas y no presta atención a los detalles.\",\n",
       "        2.34375],\n",
       "       [\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet for a beginner's listening test comment. The snippet should have a text input field for the student's name and a text area for the comment. The comment should mention that the student's performance depends on various linguistic supports such as visual aids, gestures, and slow speech.\\n\\n### Response:Comentario para boletín de notas de “listening”  para principiantes 3\\n\\n{formtext: name= nombre; cols=9} depende en gran medida de los apoyos lingüísticos (por ejemplo, visuales, gestos, habla lenta).\",\n",
       "        2.359375],\n",
       "       [\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet that allows the user to input a name and inserts it into a sentence that praises the person's ability to come up with valuable business ideas. Use a TextBlaze template that allows for user input and a sentence structure that includes the name and a compliment.\\n\\n### Response:{formtext: name=Name} frequently comes up with new ideas and business propositions that have been extremely valuable.\",\n",
       "        2.375],\n",
       "       [\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet that prompts the user to input a name with a text field of 9 columns, followed by a sentence that describes the user's behavior of completing tasks but submitting them late.\\n\\n### Response:{formtext: name= nombre; cols=9} completa todos sus deberes pero suele entregarlos tarde.\",\n",
       "        2.375],\n",
       "       [\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet that displays the next meeting day in a note, with a dropdown menu to select the day of the week, and an agenda for the upcoming weekly staff meeting. The agenda should display the day of the week and the date, and should be generated using a time function that shifts the date to the next occurrence of the selected day of the week.\\n\\n### Response:{note}Next meeting day: {formmenu: name=day; Monday; Tuesday; Wednesday; Thursday; Friday; Saturday; Sunday}{endnote: trim=right}\\nHere's the agenda for our upcoming weekly staff meeting on {time: dddd, MMMM Do; shift=>{=upper({time: ddd; at={=day}; pattern=dddd})}}.\",\n",
       "        2.421875],\n",
       "       ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nInsert the current date 15 days from now at the text cursor. Use the appropriate TextBlaze template.\\n\\n### Response:{time: MMMM Do YYYY; shift=+15D}',\n",
       "        2.421875],\n",
       "       ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet that prompts the user to enter a date of birth in the format YYYY-MM-DD using a date picker. The snippet should then calculate the age of the patient in years and display it. Use a note to calculate the age and trim the output.\\n\\n### Response:The patient was born: {formdate: YYYY-MM-DD;name=DOB}. Currently {=floor(diff/(60\\\\*60\\\\*24*365))} years old\\n{note}{diff={time: X}-{time: X; at={=DOB}}}{endnote: trim=yes}',\n",
       "        2.421875],\n",
       "       ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet that allows the user to enter text to be rewritten in simpler language. The snippet should use a language model to rewrite the text to a 6th grade reading level. The snippet should include a form paragraph for the user to enter the text to be rewritten and a note to provide context.\\n\\n### Response:{note} Enter text to rewrite:\\n{formparagraph: name=text; cols=40; rows=10}{endnote}\\n{openai-text: Rewrite the following to use language that is more appropriately geared toward a 6th grade reading level:\\n{=text}; trim=left}',\n",
       "        2.4375],\n",
       "       ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet that allows the user to input a first name with a width of 8 columns and inserts it into a sentence about struggling with letter-sound relationships. Use the appropriate {{TextBlaze template}} for the input field.\\n\\n### Response:{formtext: name=first name; cols=8} is struggling with letter-sound relationships.',\n",
       "        2.453125],\n",
       "       ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet that allows the user to select from a dropdown menu with default options, and inserts the selected option into the text. The snippet should prompt the user to choose between different options for the project, assignment, or challenge.\\n\\n### Response:I was blown away by your approach {formmenu: to this project; default=to this assignment;to this challenge}.',\n",
       "        2.453125],\n",
       "       [\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet that displays a patient's name, previous diagnosis, prescribed medication, and date prescribed. Use placeholders for patient name, previous diagnosis, and medication. The date should be automatically generated.\\n\\n### Response:Patient Name: Emily Jones\\n<br>\\nPatient has a previous diagnosis of: {formtext: name=strep throat} and was prescribed: {formmenu: Ibuprofen; default=Tylenol; Antibiotics} on 4/19/22. \\n<Br>\\nSigned,\\nJane Doe\",\n",
       "        2.46875],\n",
       "       ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet that prompts the user to enter a name in a text field with 9 columns. The snippet should output a message indicating that the user is starting to feel confident communicating in English.\\n\\n### Response:Comentario para boletín de notas para principiantes 6\\n\\n{formtext: name= nombre; cols=9} está empezando a sentirse confiado al comunicarse en Inglés-',\n",
       "        2.46875],\n",
       "       ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet that prompts the user to input a name with a text field of 9 columns, followed by a message about their performance in arithmetic.\\n\\n### Response:{formtext: name= nombre; cols=9} no está rindiendo al máximo en aritmética.',\n",
       "        2.46875],\n",
       "       [\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet that allows a teacher to input a student's name and their difficulty in understanding English texts appropriate for their beginner level. The snippet should have a text input field for the student's name and a text area for the teacher to describe the student's difficulty.\\n\\n### Response:Comentario para boletín de notas de “reading” para principiantes 1\\n\\n{formtext: name= nombre; cols=9} tiene dificultades para entender la mayoría de textos en Inglés adecuados al nivel del curso\",\n",
       "        2.484375],\n",
       "       [\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet that inserts a note to change the assignee in an issue description, followed by 16 tabs and a new line, then types 'C', waits for 2 seconds, and presses enter.\\n\\n### Response:{note}Use in an issue description to change the asignee{endnote: trim=yes}\\n{repeat: 16}{key: tab}{endrepeat}{key: enter}C{wait: delay=+2s}{key: enter}\",\n",
       "        2.5],\n",
       "       ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet that allows the user to input a name and generates a comment for an advanced writing class. The comment should state that the user can participate significantly in all appropriate shared writing exercises for their course. The input field should have a width of 9 columns.\\n\\n### Response:Comentario para boletín de notas de “writing” para avanzados 3\\n\\n{formtext: name= nombre; cols=9} pueden participar de manera significativa en todos los ejercicios de escritura compartida apropiados para su curso.',\n",
       "        2.5],\n",
       "       ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet that prompts the user to input a name with a text field of 9 columns, followed by a statement about seeking help for arithmetic problems. The statement should be customizable.\\n\\n### Response:{formtext: name= nombre; cols=9} se esfuerza por resolver problemas de aritmética, pero podría beneficiarse de pedir ayuda más a menudo.',\n",
       "        2.515625],\n",
       "       [\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet that prompts for a student's name and allows them to input their ability to recognize and understand printed English in their environment. The input should be a text field with a width of 9 columns.\\n\\n### Response:Comentario para boletín de notas de “reading” para estudiantes intermedios 3\\n\\n{formtext: name= nombre; cols=9} reconoce y comprende fácilmente la el inglés impreso de su entorno (es decir, etiquetas, señales, logotipos).\",\n",
       "        2.671875],\n",
       "       ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet that prompts the user to enter a name in a text field with 9 columns and evaluates their understanding of English verb tenses in writing.\\n\\n### Response:Comentario para boletín de notas de “writing” para avanzados 5\\n\\n{formtext: name= nombre; cols=9} demuestra la comprensión de los tiempos verbales en inglés al escribir.',\n",
       "        2.703125],\n",
       "       ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet that allows a user to input a name with a width of 9 columns and provides feedback on their ability to change verb tenses in English writing.\\n\\n### Response:Comentario para boletín de notas de “writing” para principiantes 9\\n\\n{formtext: name= nombre; cols=9} muestra una capacidad limitada para cambiar los tiempos verbales en la escritura en inglés.',\n",
       "        2.71875],\n",
       "       ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nInsert a form element that allows the user to input text with a label \"nombre\" and a width of 9 columns. The text should indicate that the user can understand some common, specific, and practiced words.\\n\\n### Response:Comentario para boletín de notas de “reading” para principiantes 2\\n\\n{formtext: name= nombre; cols=9} puede comprender algunas palabras comunes, muy usadas, concretas y practicadas.',\n",
       "        2.734375],\n",
       "       ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a snippet that prompts the user to input a name with a text field of 9 columns and checks if the language used in the majority of the compositions is appropriate for the level of the course.\\n\\n### Response:Comentario para boletín de notas de “writing” para avanzados 2\\n\\n{formtext: name= nombre; cols=9} usa lenguaje propio del nivel del curso en la mayoría de redacciones.',\n",
       "        2.921875]], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by = 'loss').tail(n=30).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a48c79f1-e04e-4dfc-9c09-1d7d963f0e7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T09:15:17.221882Z",
     "iopub.status.busy": "2023-06-20T09:15:17.221613Z",
     "iopub.status.idle": "2023-06-20T09:15:17.245185Z",
     "shell.execute_reply": "2023-06-20T09:15:17.244015Z",
     "shell.execute_reply.started": "2023-06-20T09:15:17.221864Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/notebooks/2023_06_llm_training/Lit-Parrot/lit_parrot/tokenizer.py:51\u001b[0m, in \u001b[0;36mTokenizer.decode\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     50\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m [tensor\u001b[38;5;241m.\u001b[39mitem()] \u001b[38;5;28;01mif\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b835a5c-c667-41a0-b390-8f48f987041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = fabric.setup(model)\n",
    "\n",
    "tokenizer = Tokenizer(checkpoint_dir / \"tokenizer.json\", checkpoint_dir / \"tokenizer_config.json\")\n",
    "sample = {\"instruction\": prompt, \"input\": input}\n",
    "prompt = generate_prompt(sample)\n",
    "encoded = tokenizer.encode(prompt, device=model.device)\n",
    "prompt_length = encoded.size(0)\n",
    "max_returned_tokens = prompt_length + max_new_tokens\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "y = generate(\n",
    "    model,\n",
    "    encoded,\n",
    "    max_returned_tokens,\n",
    "    max_seq_length=max_returned_tokens,\n",
    "    temperature=temperature,\n",
    "    top_k=top_k,\n",
    "    eos_id=tokenizer.eos_id,\n",
    ")\n",
    "t = time.perf_counter() - t0\n",
    "\n",
    "model.reset_cache()\n",
    "output = tokenizer.decode(y)\n",
    "output = output.split(\"### Response:\")[1].strip()\n",
    "fabric.print(output)\n",
    "\n",
    "tokens_generated = y.size(0) - prompt_length\n",
    "fabric.print(f\"\\n\\nTime for inference: {t:.02f} sec total, {tokens_generated / t:.02f} tokens/sec\", file=sys.stderr)\n",
    "if fabric.device.type == \"cuda\":\n",
    "    fabric.print(f\"Memory used: {torch.cuda.max_memory_reserved() / 1e9:.02f} GB\", file=sys.stderr)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
